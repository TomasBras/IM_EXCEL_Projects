<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>Excel AI Assistant</title>

    <!-- Font -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600&display=swap" rel="stylesheet">

   <style>
    body {
        background: #f3f4f6; /* Cinza claro suave */
        color: #333;
        font-family: "Inter", sans-serif;
        margin: 0;
        padding: 0;
    }

    /* HEADER */
    header {
        padding: 20px 40px;
        background: #ffffff;
        font-size: 26px;
        font-weight: 600;
        letter-spacing: 0.5px;
        color: #168022; /* Azul Office pastel */
        border-bottom: 1px solid #d6d6d6;
        text-align: center;
        box-shadow: 0 2px 6px rgba(0,0,0,0.06);
    }

    /* MAIN CONTAINER */
    .bottomNav {
        position: fixed;
        bottom: 2%;
        width: 100%;
        display: flex;
        flex-direction: column;
        align-items: center;
    }

    #response {
        background: #ffffff;
        padding: 15px 25px;
        border-radius: 14px;
        box-shadow: 0px 4px 12px rgba(0,0,0,0.08);
        border: 1px solid #e1e1e1;
        font-size: 18px;
        max-width: 80%;
        min-height: 30px;
        transition: 0.3s;
        color: #0f5132;
    }

    /* MIC AREA */
    .container {
        display: flex;
        align-items: center;
        justify-content: start;
        gap: 30px;
        width: 75%;
        padding: 22px;
        margin-top: 25px;
        background: #ffffff;
        border-radius: 22px;
        border: 1px solid #e4e4e7;
        box-shadow: 0px 4px 16px rgba(0,0,0,0.06);
    }

    .mic {
        width: 140px;
        cursor: pointer;
        transition: 0.3s;
        filter: drop-shadow(0px 0px 6px rgba(0, 150, 90, 0.25));
    }

    .mic:hover {
        transform: scale(1.05);
        filter: drop-shadow(0px 0px 10px rgba(0, 150, 90, 0.35));
    }

    /* TRANSCRIPT TEXT */
    #transcript {
        font-size: 22px;
        color: #168022; /* Azul suave */
        letter-spacing: 0.5px;
        font-weight: 400;
    }
</style>

</head>

<body>

<header>Excel AI Assistant</header>

<div class="bottomNav">
    <div id="response"></div>

    <div class="container">

        <!-- MICROPHONE SVG (unchanged) -->
        <svg class="mic" id="mic" version="1.1" xmlns="http://www.w3.org/2000/svg"
             x="0px" y="0px" viewBox="0 0 100 100" xml:space="preserve">
            <style type="text/css">
                .st0{fill:#168022;}
                .st1{opacity:0.2;}
                .st2{fill:#1e293b;}
                .st3{fill:#168022;}
                .st4{fill:#ffffff;}
            </style>
            <circle class="st0" cx="50" cy="50" r="32" />
            <g id="Layer_1" transform="translate(18,18)">
                <g class="st1">
                    <path class="st2" d="M32,41.5c3.3,0,6-2.7,6-6v-18c0-3.3-2.7-6-6-6s-6,2.7-6,6v18C26,38.8,28.7,41.5,32,41.5z"/>
                </g>
                <g class="st1">
                    <path class="st2" d="M32,48.2c-7.2,0-13-5.8-13-13v-3.8c0-0.8,0.7-1.5,1.5-1.5s1.5,0.7,1.5,1.5v3.8c0,5.5,4.5,10,10,10
                        s10-4.5,10-10v-3.8c0-0.8,0.7-1.5,1.5-1.5s1.5,0.7,1.5,1.5v3.8C45,42.4,39.2,48.2,32,48.2z"/>
                </g>
                <g class="st1">
                    <path class="st2" d="M32,55c-0.8,0-1.5-0.7-1.5-1.5v-6c0-0.8,0.7-1.5,1.5-1.5s1.5,0.7,1.5,1.5v6C33.5,54.3,32.8,55,32,55z"/>
                </g>
                <g class="st1">
                    <path class="st2" d="M37,56H27c-0.8,0-1.5-0.7-1.5-1.5S26.2,53,27,53h10c0.8,0,1.5,0.7,1.5,1.5S37.8,56,37,56z"/>
                </g>
                <path class="st3" d="M32,39.5c3.3,0,6-2.7,6-6v-18c0-3.3-2.7-6-6-6s-6,2.7-6,6v18C26,36.8,28.7,39.5,32,39.5z" />
                <path class="st4" d="M32,46.2c-7.2,0-13-5.8-13-13v-3.8c0-0.8,0.7-1.5,1.5-1.5s1.5,0.7,1.5,1.5v3.8c0,5.5,4.5,10,10,10
                    s10-4.5,10-10v-3.8c0-0.8,0.7-1.5,1.5-1.5s1.5,0.7,1.5,1.5v3.8C45,40.4,39.2,46.2,32,46.2z"/>
                <path class="st4" d="M32,53c-0.8,0-1.5-0.7-1.5-1.5v-6c0-0.8,0.7-1.5,1.5-1.5s1.5,0.7,1.5,1.5v6C33.5,52.3,32.8,53,32,53z"/>
                <path class="st4" d="M37,54H27c-0.8,0-1.5-0.7-1.5-1.5S26.2,51,27,51h10c0.8,0,1.5,0.7,1.5,1.5S37.8,54,37,54z"/>
            </g>
        </svg>

        <div id="transcript"></div>
    </div>
</div>
    <script src="https://cdn.jsdelivr.net/npm/@svgdotjs/svg.js@latest/dist/svg.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.7/dist/bundle.min.js"></script>
    <script src="js/mmi.js"></script>
    <script src="js/globals.js"></script>
    <script src="js/jquery-3.6.4.min.js"></script>
    <script src="js/webtoolkit.utf8.js"></script>


    <script type="text/javascript" src="js/recorder.js"></script>
    <script type="text/javascript" src="js/microphone.js"></script>
    <script type="text/javascript" src="kws__/edge-impulse-standalone.js"></script>
    <script type="text/javascript" src="kws__/run-impulse.js"></script>

    <script type="module">

        var isOnKWS = false;
        const sensor = new MicrophoneSensor();
        let classifyCache = {};
        let allData = [];
        let allClassifications = [];
        let casa_vivaStarted = null;

        async function startkws() {
            classifyCache = {};
            allData = [];
            allClassifications = [];
            casa_vivaStarted = null;

            isOnKWS = false;
            //await sensor.takeSample(200, 16000, () => {});
            sensor.takeSample(1000, 16000, () => { }).then(onSampleComplete);
        }

        setTimeout(function () {
            classifyCache = {};
            allData = [];
            allClassifications = [];
            casa_vivaStarted = null;
        }, 60 * 60 * 1000);

        const onSampleComplete = (obj) => {
            if (!isOnKWS)
                sensor.takeSample(500, 16000, () => { }).then(onSampleComplete);

            allData = allData.concat(obj.values);
            //console.log(Date.now(), 'allData is', allData.length / 16000, 'seconds');

            const windowSize = 3 * 16000;
            const windowStep = 0.5 * 16000;
            const classifyWindowLength = 0.5 * 16000;
            const classifyWindowOverlap = 0.25 * 16000;

            // if we have at least one window of data...
            if (allData.length >= windowSize) {
                let window = allData.slice(allData.length - windowSize, allData.length);

                let noiseCount = 0;
                let casa_vivaCount = 0;
                let uncertainCount = 0;

                // in here we'll take 1 second slices, with 300 ms. overlap that we then classify (total 14 windows)
                console.time('classifyWindow');
                for (let wx = 0; wx <= windowSize - classifyWindowLength; wx += classifyWindowOverlap) {
                    const cacheKey = allData.length - windowSize + wx;

                    let classifyResult;
                    if (!classifyCache[cacheKey]) {
                        let slice = window.slice(wx, wx + classifyWindowLength);

                        classifyCache[cacheKey] = classifier.classify(slice, false);
                    }

                    classifyResult = classifyCache[cacheKey];
                    let noise = classifyResult.results.find(r => r.label === 'noise').value;
                    let casa_viva = classifyResult.results.find(r => r.label === 'casa_viva').value;

                    if (casa_viva > .3)
                        console.log(casa_viva);
                    if (noise >= 0.6) {
                        noiseCount++;
                    }
                    else if (casa_viva >= 0.6) {
                        casa_vivaCount++;

                        if (!isOnKWS) {
                            recognition.start();
                            circle.animate(20, 0, 'now').attr({ fill: '#00a431' });
                            transcriptDiv.textContent = "...";
                            isOnKWS = true;
                        }

                    }
                    else {
                        uncertainCount++;
                    }
                }
            }
            //console.timeEnd('classifyWindow');
        };

        async function InitializeKWS() {
            const classifier = window.classifier = new EdgeImpulseClassifier();
            await classifier.init();
            await sensor.init();
            if (!sensor.hasSensor()) {
                alert('Your device does not seem to have a microphone');
            }
            // start up the sensor
            //await sensor.takeSample(200, 16000, () => {});

            // then take 1s of data
            sensor.takeSample(500, 16000, () => { }).then(onSampleComplete);
        };
        //InitializeKWS();


        import { interpolateGreens } from "https://cdn.skypack.dev/d3-scale-chromatic@3"

        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        const recognition = new SpeechRecognition();
        recognition.continuous = false;
        recognition.interimResults = true;
        recognition.lang = 'pt-PT';


        var circle = SVG.find('.st0');//.fill('#ccc');
        const startBtn = document.getElementById('start-btn');
        const transcriptDiv = document.getElementById('transcript');
        const energyDiv = document.getElementById('energy');

        var firstSent = "Como posso ajudar no Excel? Descubra todos os comandos que temos disponíveis.";
        transcriptDiv.textContent = firstSent;
        var resetfunc;


        recognition.onerror = function (event) {
            console.error("REC ERROR" + event.error);
            transcriptDiv.innerHTML = firstSent;
            circle.animate(20, 0, 'now').attr({ fill: '#000' });
            //    startkws();
        };

        //recognition.onresult = function (event) {
        //    speechActive = false;
        //    var interim_transcript = '';
        //    var final_transcript = '';

        //    for (var i = event.resultIndex; i < event.results.length; ++i) {
        //        if (event.results[i].isFinal) {
        //            //if(event.results[i][0].confidence>0.6)
        //            energyDiv.textContent += event.results[i][0].confidence;
        //            {
        //                final_transcript = "";
        //                console.log("++" + event.results[i][0].transcript + "++");
        //                final_transcript = event.results[i][0].transcript.trim();
        //                /*var sentence = event.results[i][0].transcript.trim().toLowerCase();
        //                if(sentence.startsWith("casa viva") || sentence.startsWith("viva") || sentence.startsWith("aviva") || sentence.startsWith("sa viva") || sentence.startsWith("da viva") ||sentence.startsWith("ora viva"))
        //                {
        //                  var indSent = sentence.indexOf("viva");
        //                  final_transcript= sentence.slice(indSent+5);
        //                }*/
        //            }

        //            if (final_transcript.length > 2) {
        //                final_transcript = final_transcript.charAt(0).toUpperCase() + final_transcript.slice(1);
        //                transcriptDiv.innerHTML = "<span style='color:#00b44e'><b>" + final_transcript + "</b></span>";

        //                sendMMI(final_transcript);
        //                circle.animate(20, 0, 'now').attr({ fill: '#000' });
        //            //    startkws();
        //            } else {
        //                transcriptDiv.innerHTML = "<span style='color:#ff9494'><b>Desculpe nao consegui ententer.</b></span>";
        //            }

        //            //resetfunc = setTimeout(function () {
        //            //    transcriptDiv.innerHTML = firstSent;
        //            //}, 3000);

        //            speechActive = false;
        //        } else {
        //            //if(event.results[i][0].confidence>0.6)
        //            {
        //                console.log(event.results[i][0].transcript + " -- " + i);
        //                var sentence = event.results[i][0].transcript.trim().toLowerCase();
        //                /*if(sentence.startsWith("casa viva") || sentence.startsWith("viva") || sentence.startsWith("aviva") || sentence.startsWith("sa viva") || sentence.startsWith("da viva") ||sentence.startsWith("ora viva") ){
        //                  var indSent = sentence.indexOf("viva");
        //                  final_transcript= sentence.slice(indSent+5);
        //                }*/

        //            }
        //            transcriptDiv.textContent = event.results[i][0].transcript.trim().toLowerCase();
        //        }
        //    }
        //};

        // Start recognition on page load
        window.onload = function () {
            console.log("Starting voice recognition...");
            recognition.start();
        };

        // Handle recognition results
        recognition.onresult = function (event) {
            let final_transcript = '';
            let interim_transcript = '';

            // Process each result
            for (let i = event.resultIndex; i < event.results.length; ++i) {
                const result = event.results[i];
                const confidence = result[0].confidence;

                if (result.isFinal) {
                    final_transcript = result[0].transcript.trim();
                    console.log(`Final transcript: "${final_transcript}" (Confidence: ${confidence})`);

                    if (confidence < 0.8) {
                        transcriptDiv.innerHTML = "<span style='color:#ff9494'><b>Não percebi, repita por favor.</b></span>";
                        sendMMI(final_transcript);
                    } else if (confidence >= 0.8 && confidence <= 0.9) {
                        transcriptDiv.innerHTML = "<span style='color:#b3b3b3'><b>(Confiança insuficiente, ignorado)</b></span>";
                    } else {
                        transcriptDiv.innerHTML = `<span style='color:#00b44e'><b>${final_transcript}</b></span>`;
                        sendMMI(final_transcript); // Pass to processing logic
                    }
                } else {
                    interim_transcript += result[0].transcript.trim() + ' ';
                    transcriptDiv.textContent = interim_transcript;
                }
            }

            //// Reset feedback display after 5 seconds
            //resetTimeout = setTimeout(() => {
            //    transcriptDiv.textContent = "Diga algo para continuar.";
            //}, 5000);
        };

        // Handle recognition errors
        recognition.onerror = function (event) {
            console.error(`Recognition error: ${event.error}`);
            transcriptDiv.innerHTML = "<span style='color:#ff9494'><b>Erro na escuta. Reiniciando...</b></span>";
            setTimeout(() => recognition.start(), 1000); // Restart recognition
        };

        // Restart recognition when it ends
        recognition.onend = function () {
            console.log("Recognition ended. Restarting...");
            recognition.start();
        };

        // Click mic to start voice recognition !!
        $(".mic").on('click', function () {
            recognition.start();
            console.log("Start voice recognition");
        })


        var vadActive = false;
        var speechActive = false;

        async function main() {
            const myvad = await vad.MicVAD.new({

                onSpeechEnd: (audio) => {
                    // do something with `audio` (Float32Array of audio samples at sample rate 16000)...
                    //transcriptDiv.textContent += "-";
                    vadActive = false;
                    setTimeout(function () {
                        if (speechActive) recognition.stop();
                        speechActive = false;
                    }, 3000);
                },
                onSpeechStart: () => {
                    //transcriptDiv.textContent += " ->";
                    if (!speechActive) {
                        speechActive = true;
                        recognition.start();
                        transcriptDiv.textContent = "...";
                    }
                    clearTimeout(resetfunc);
                    vadActive = true;
                },
                onFrameProcessed: (probs) => {
                    if (vadActive || speechActive) {
                        const indicatorColor = interpolateGreens(probs.isSpeech / 1.5);
                        //circle.fill(indicatorColor);
                        circle.animate(20, 0, 'now').attr({ fill: indicatorColor });
                    }
                    //    energyDiv.textContent = probs.isSpeech + "--" + probs.notSpeech;
                    //document.body.style.setProperty("--indicator-color", indicatorColor)
                },
            })
            //myvad.start()
        }
        //main()

        if ('speechSynthesis' in window) {
            console.log('Your browser <strong>supports</strong> speech synthesis.');
        }

        var ttsSpeaker;
        window.speechSynthesis.onvoiceschanged = function (e) {
            var voices = speechSynthesis.getVoices();
            ttsSpeaker = voices[0];
            for (let i = 0; i < voices.length; i++) {
                if (voices[i].lang == "pt-PT") {
                    console.log(voices[i]);
                    if (voices[i].name.includes("Duarte")) ttsSpeaker = voices[i];
                }


            }

            console.log(ttsSpeaker);
        };

        function speak(text) {

            var msg = new SpeechSynthesisUtterance();
            msg.text = text;

            // Set the attributes.
            msg.volume = parseFloat(1);
            msg.rate = parseFloat(1.1);
            msg.pitch = parseFloat(1);

            msg.voice = ttsSpeaker;

            window.speechSynthesis.speak(msg);
        }
        /////////////////////////////////////////


        var mmiCli_1 = null;
        mmiCli_1 = new MMIClient(null, mmi_fusion + "SPEECHIN");


        function sendMMI(final_transcript) {

            var obj = new Object();
            obj.text = final_transcript;
            $.post("http://localhost:5005/model/parse", JSON.stringify(obj), function (data) {
                console.log(data);

                var message;

                switch (data.intent.name) {

                    // -------------------------
                    case 'calcular_media':
                        message = {
                            intent: 'calcular_media',
                            aluno_nome: data.entities.find(e => e.entity === "aluno_nome")?.value || null,
                            aluno_numero: data.entities.find(e => e.entity === "aluno_numero")?.value || null
                        };
                        break;

                    // -------------------------
                    case 'destacar_aprovados_reprovados':
                        message = { intent: 'destacar_aprovados_reprovados' };
                        break;

                    // -------------------------
                    case 'identificar_melhoria':
                        message = { intent: 'identificar_melhoria' };
                        break;

                    // -------------------------
                    case 'inserir_colunas':
                        message = {
                            intent: 'inserir_colunas',
                            coluna_nome: data.entities.find(e => e.entity === "coluna_nome")?.value || null,
                            coluna_teste: data.entities.find(e => e.entity === "coluna_teste")?.value || null,
                            teste_numero: data.entities.find(e => e.entity === "teste_numero")?.value || null
                        };
                        break;

                    // -------------------------
                    case 'inserir_perguntas':
                        message = {
                            intent: 'inserir_perguntas',
                            teste_numero: data.entities.find(e => e.entity === "teste_numero")?.value || null
                        };
                        break;

                    // -------------------------
                    case 'gerar_grafico_turma':
                        message = { intent: 'gerar_grafico_turma' };
                        break;

                    // -------------------------
                   case 'gerar_grafico_barras_aluno':
                        message = {
                            intent: 'gerar_grafico_barras_aluno',
                            aluno_numero: data.entities.find(e => e.entity === "aluno_numero")?.value || null,
                            aluno_nome: data.entities.find(e => e.entity === "aluno_nome")?.value || null
                        };
                        break;

                    // -------------------------
                    case 'gerar_grafico_perguntas_t2':
                        message = { intent: 'gerar_grafico_perguntas_t2' };
                        break;

                    // -------------------------
                    case 'atualizar_notas':
                        message = {
                            intent: 'atualizar_notas',
                            aluno_numero: data.entities.find(e => e.entity === "aluno_numero")?.value || null,
                            pergunta: data.entities.find(e => e.entity === "pergunta")?.value || null,
                            valores: data.entities.filter(e => e.entity === "valores").map(e => e.value)
                        };
                        break;

                    // -------------------------
                    case 'guardar_ficheiro':
                        message = {
                            intent: 'guardar_ficheiro',
                            nome_ficheiro: data.entities.find(e => e.entity === "nome_ficheiro")?.value || null
                        };
                        break;

                    // -------------------------
                    case 'operacoes_matematicas':
                        message = { intent: 'operacoes_matematicas' };
                        break;

                    // -------------------------
                    case 'atualizar_valores':
                        message = {
                            intent: 'atualizar_valores',
                            valores: data.entities.filter(e => e.entity === "valores").map(e => e.value)
                        };
                        break;

                    // -------------------------
                    case 'apagar_todos_graficos':
                        message = { intent: 'apagar_todos_graficos' };
                        break;

                    // -------------------------
                    case 'greet':
                    case 'ask_how_are_you':
                    case 'respond_how_am_i':
                    case 'helper':
                        message = { intent: data.intent.name };
                        break;

                    // -------------------------
                    default:
                        console.warn("Intent não reconhecida:", data.intent.name);
                        return;
                }


                var messaget = btoa(unescape(encodeURIComponent(final_transcript)));
                var result = { "recognized": ["SPEECH", "SPEECHIN", "APP"], "text": messaget, "nlu": message };
                mmiCli_1.sendToIM(new LifeCycleEvent("SPEECHIN", "IM", "text-1", "ctx-1").
                    doExtensionNotification(new EMMA("text-", "text", "command", 1, 0).
                        setValue(JSON.stringify(result))));
            });
        }

        /*

                  */
        // sendMMI("mudar para azul o circulo");


        var mmiCli_Out_add = "wss://" + host + ":8005/IM/USER1/";
        var mmiCli_Out = null;
        mmiCli_Out = new MMIClientSocket(mmiCli_Out_add + "SPEECHOUT");
        mmiCli_Out.onMessage.on(im1MessageHandler);
        mmiCli_Out.onOpen.on(socketOpenHandler);
        mmiCli_Out.openSocket();


        function socketOpenHandler(event) {
            console.log("---------------openSocketHandler---------------")

            if (mmiCli_Out.socket.readyState !== WebSocket.OPEN) {
                return;
            }
        }

        function im1MessageHandler(data) {

            console.log("--------------im1MessageHandler---------------");

            if (data != null && data != "RENEW" && data != "OK") {

                console.log(data);

                var content = $(data).find("emma\\:interpretation").first().text().trim();

                if (typeof content == 'string') {
                    try {
                        // Try to parse XML
                        var xml = $.parseXML(content.replace(/\\"/g, "\"").slice(1, -1));

                        // Extract sentence
                        let text = $(xml).find("p").text();
                        //let text = Utf8.decode(atob(sentence.slice(2,-1)));

                        console.log(text);
                        speak(text);

                        $("#response").html(text);
                        $("#response").addClass("container");
                        $("#response").addClass("responseText");

                        setTimeout(function () {
                            $("#response").html("");
                            $("#response").removeClass("container");
                            $("#response").removeClass("responseText");
                        }, 3000);

                    }
                    catch (e) { console.log(e); }

                }
            }
        }

        var mmiCli_1 = null;
        mmiCli_1 = new MMIClient(null, "https://" + host + ":8000/IM/USER1/APPSPEECH")

        function sendToVoice(texto) {
            //let speak = "&lt;speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.w3.org/2001/10/synthesis http://www.w3.org/TR/speech-synthesis/synthesis.xsd\" xml:lang=\"pt-PT\"&gt;&lt;p&gt;" + "quadrado" + "&lt;/p&gt;&lt;/speak&gt";
            let speak = "<speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.w3.org/2001/10/synthesis http://www.w3.org/TR/speech-synthesis/synthesis.xsd\" xml:lang=\"pt-PT\"><p>" + texto + "</p></speak>";
            var result = speak;
            mmiCli_1.sendToIM(new LifeCycleEvent("APPSPEECH", "IM", "text-1", "ctx-1").
                doStartRequest(new EMMA("text-", "text", "command", 1, 0).
                    setValue(JSON.stringify(result))));
        }

        /////////////////////////////////////////


        // sendMMI("Ligar as luzes")
    </script>



</body>
</html>